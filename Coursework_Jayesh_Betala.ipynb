{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fmoI0fOXv5i"
      },
      "source": [
        "# **Logistic Code**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import glob # The glob module is used for Unix style pathname pattern expansion.\n",
        "import imageio # The library that provides an easy interface to read and write a wide range of image data\n",
        "import os\n",
        "import PIL\n",
        "import time\n",
        "import gdown\n",
        "\n",
        "from IPython import display"
      ],
      "metadata": {
        "id": "yC6AiZxIKFTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load MNIST Database\n",
        "\n",
        "# Using underscore to omit the label arrays\n",
        "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data() \n",
        "\n",
        "\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
        "train_images = (train_images - 127.5) / 127.5 # Normalize the images to [-1, 1]\n",
        "\n",
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "# Batch and shuffle the data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "pLG6RGrzKGrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generator Model\n",
        "\n",
        "def generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 14, 14, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    print(model.summary())\n",
        "\n",
        "    return model\n",
        "\n",
        "generator = generator_model()"
      ],
      "metadata": {
        "id": "Nkwgn0TNKG0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-ux2xrq3pNo"
      },
      "outputs": [],
      "source": [
        "# Create a random noise and generate a sample\n",
        "noise = tf.random.normal([1, 100])\n",
        "generated_image = generator(noise, training=False)\n",
        "# Visualize the generated sample\n",
        "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3rTe-6g3qhn"
      },
      "outputs": [],
      "source": [
        "#@title Discriminator Model\n",
        "\n",
        "def discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    \n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "\n",
        "    print(model.summary())\n",
        "\n",
        "    return model\n",
        "\n",
        "discriminator = discriminator_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKk6IIjD3tAU"
      },
      "outputs": [],
      "source": [
        "# This method returns a helper function to compute cross entropy loss\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjSvRyANDOuZ"
      },
      "source": [
        "# **Training Code**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYc38wns3w9l"
      },
      "outputs": [],
      "source": [
        "# @title Training Steps\n",
        "\n",
        "# EPOCHS = 3000 #@param{type: \"integer\"} \n",
        "# num_examples_to_generate = 16\n",
        "# noise_dim = 100\n",
        "# seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
        "\n",
        "# # tf.function annotation causes the function to be \"compiled\" as part of the training\n",
        "# @tf.function\n",
        "# def train_step(images):\n",
        "  \n",
        "#     # 1 - Create a random noise to feed it into the model for the image generation\n",
        "#     noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
        "    \n",
        "#     # 2 - Generate images and calculate loss values\n",
        "#     # The method records operations for automatic differentiation\n",
        "#     with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "#       generated_images = generator(noise, training=True)\n",
        "\n",
        "#       real_output = discriminator(images, training=True)\n",
        "#       fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "#       gen_loss = generator_loss(fake_output)\n",
        "#       disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "#     # 3 - Calculate gradients using loss values and model variables\n",
        "#     # \"gradient\" method computes the gradient using operations recorded in context of this tape (gen_tape and disc_tape).\n",
        "    \n",
        "#     # It accepts a target (e.g., gen_loss) variable and a source variable (e.g.,generator.trainable_variables)\n",
        "#     # target --> a list or nested structure of Tensors or Variables to be differentiated.\n",
        "#     # source --> a list or nested structure of Tensors or Variables.\n",
        "#     # target will be differentiated against elements in sources.\n",
        "\n",
        "#     # \"gradient\" method returns a list or nested structure of Tensors or IndexedSlices, or None, one for each element in sources. \n",
        "#     # Returned structure is the same as the structure of sources.\n",
        "#     gradients_of_generator = gen_tape.gradient(gen_loss, \n",
        "#                                                generator.trainable_variables)\n",
        "#     gradients_of_discriminator = disc_tape.gradient(disc_loss, \n",
        "#                                                 discriminator.trainable_variables)\n",
        "    \n",
        "#     # 4 - Process  Gradients and Run the Optimizer\n",
        "#     # \"apply_gradients\" method processes aggregated gradients. \n",
        "#     \"\"\"\n",
        "#     Example to show use of apply_gradients:\n",
        "#     grads = tape.gradient(loss, vars)\n",
        "#     grads = tf.distribute.get_replica_context().all_reduce('sum', grads)\n",
        "#     # Processing aggregated gradients.\n",
        "#     optimizer.apply_gradients(zip(grads, vars), experimental_aggregate_gradients=False)\n",
        "#     \"\"\"\n",
        "#     generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "#     discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_K_8gEa3yMD"
      },
      "outputs": [],
      "source": [
        "# @title Function to Generate Images\n",
        "\n",
        "# def generate_and_save_images(model, epoch, test_input):\n",
        "#   # 1 - Generate images\n",
        "#   predictions = model(test_input, training=False)\n",
        "\n",
        "#   # 2 - Plot the generated images\n",
        "#   fig = plt.figure(figsize=(4,4))\n",
        "#   for i in range(predictions.shape[0]):\n",
        "#       plt.subplot(4, 4, i+1)\n",
        "#       plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "#       plt.axis('off')\n",
        "\n",
        "#   # 3 - Save the generated images\n",
        "#   plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "\n",
        "#   # 4 - Display the generated images\n",
        "#   plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-hUjZMr30D_"
      },
      "outputs": [],
      "source": [
        "# @title Train GAN\n",
        "\n",
        "# import time\n",
        "# from IPython import display # A command shell for interactive computing in Python.\n",
        "\n",
        "# def train(dataset, epochs):\n",
        "#   # A. For each epoch, do the following:\n",
        "#   for epoch in range(epochs):\n",
        "#     start = time.time()\n",
        "#     # 1 - For each batch of the epoch, \n",
        "#     for image_batch in dataset:\n",
        "#       # Run the custom \"train_step\" function we just declared above\n",
        "#       train_step(image_batch)\n",
        "\n",
        "#     # 2 - Produce images for the GIF as we go\n",
        "#     display.clear_output(wait=True)\n",
        "#     generate_and_save_images(generator,\n",
        "#                              epoch + 1,\n",
        "#                              seed)\n",
        "\n",
        "#     # 3 - Print out the completed epoch no. and the time spent\n",
        "#     print ('Epoch {} took {} seconds'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "#   # B. Generate a final image after the training is completed\n",
        "#   display.clear_output(wait=True)\n",
        "#   generate_and_save_images(generator,\n",
        "#                            epochs,\n",
        "#                            seed)\n",
        "  \n",
        "# train(train_dataset, EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Save model to GDrive\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "\n",
        "# gen_save_name = 'generator' \n",
        "# gen_save_name += '.tf'  \n",
        "# disc_save_name = 'discriminator' \n",
        "# disc_save_name += '.tf' \n",
        "\n",
        "# path = 'My Drive/Computational_Creativity/models/' \n",
        "# full_path_g = F\"/content/gdrive/{path}{gen_save_name}\" \n",
        "# full_path_d = F\"/content/gdrive/{path}{disc_save_name}\" \n",
        "\n",
        "# generator.save(full_path_g, save_format='tf')\n",
        "# discriminator.save(full_path_d, save_format='tf')"
      ],
      "metadata": {
        "id": "mmef4t5eRVs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yn-Q_VYbEznN"
      },
      "source": [
        "# **Generation Code**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Saved Model\n",
        "\n",
        "url = \"https://drive.google.com/drive/folders/1A5DKYRanMbaRs-oH35yOjBbBd6mqPPqK\"\n",
        "download_successful = None \n",
        "while download_successful == None:\n",
        "  download_successful = gdown.download_folder(url, quiet=True, use_cookies=False)\n",
        "  os.system('rm ~/.cache/gdown/cookies.json')\n",
        "full_path_g = \"/content/models/generator.tf\"\n",
        "full_path_d = \"/content/models/discriminator.tf\"\n",
        "generator = tf.keras.models.load_model(full_path_g)\n",
        "discriminator = tf.keras.models.load_model(full_path_d)"
      ],
      "metadata": {
        "id": "AQfiAi89RMCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsFiO-3x33pd"
      },
      "outputs": [],
      "source": [
        "#@title Show Images\n",
        "\n",
        "SIZE=16\n",
        "for samples in range(0,10):\n",
        "  print(\"Sample:\", samples)\n",
        "  noise = tf.random.normal([SIZE, 100])\n",
        "  predictions = generator.predict(noise)\n",
        "  fig = plt.figure(figsize=(4,4))\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 4, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "    # Locally save images for the runtime\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(samples))\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create GIF\n",
        "\n",
        "# import glob # The glob module is used for Unix style pathname pattern expansion.\n",
        "# import imageio # The library that provides an easy interface to read and write a wide range of image data\n",
        "\n",
        "anim_file = 'handwritten.gif'\n",
        "\n",
        "with imageio.get_writer(anim_file, mode='I') as writer2:\n",
        "  filenames = glob.glob('image*.png')\n",
        "  filenames = sorted(filenames)\n",
        "  for filename in filenames:\n",
        "    # print(filename)\n",
        "    image = imageio.imread(filename)\n",
        "    writer2.append_data(image)\n",
        "  # image = imageio.imread(filename)\n",
        "  # writer.append_data(image)\n",
        "  \n",
        "display.Image(open('handwritten.gif','rb').read())"
      ],
      "metadata": {
        "id": "nUfYfjro0TH-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "Coursework_Jayesh_Betala.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}